return(res)
}
#' Search SRR accession IDs using projectID
#' @param projectID character, the project accession ID to search in sra database
#' (https://www.ncbi.nlm.nih.gov/sra). This ID can be searched by
#' \link{\code{searchProjectID}} function.
#' @param timeout numeric, the number of seconds to wait before killing the searching process.
#' @return a SRR documents "runinfo" data frame containing 47 columns, which are
#' Run, ReleaseDate, LoadDate, spots, bases, spots_with_mates, avgLength,
#' size_MB, AssemblyName, download_path, Experiment, LibraryName, LibraryStrategy,
#' LibrarySelection, LibrarySource, LibraryLayout, InsertSize, InsertDev,
#' Platform, Model, SRAStudy, BioProject, Study_Pubmed_id, ProjectID, Sample,
#' BioSample, SampleType, TaxID, ScientificName, SampleName, g1k_pop_code, source,
#' g1k_analysis_group, Subject_ID, Sex, Disease, Tumor, Affection_Status, Analyte_Type,
#' Histological_Type, Body_Site, CenterName, Submission, dbgap_study_accession,
#' Consent, RunHash, and ReadHash.
#' @import funcTools
#' @export
#' @examples {
#' \dontrun{
#' searchSrrID()
#' searchSrrID("PRJNA543132")
#' }
#' }
searchSrrID = function(projectID = "PRJNA540657", timeout = 60){
format = "runinfo"
cmd = sprintf('esearch -db sra -query "%s" | efetch -format %s',
projectID, format)
system("which esearch")
res1 = system(cmd, intern = T, timeout = timeout)
if (length(res1) == 0){
return(NULL)
}
title = strSplit(grep("^Run", res1, value = T), ",")[1,]
details = as.data.frame(strSplit(grep("^SRR", res1, value = TRUE), ","), stringsAsFactors = F)
colnames(details) = title
return(details)
}
#' Search SRR accession IDs using projectID
#' @param srrIDs character, the SRR accession ID to download. This ID can be searched by
#' \link{\code{searchSrrID}} function.
#' @param timeout numeric, the number of seconds to wait before killing the searching process.
#' @return a SRR documents "runinfo" data frame containing 47 columns, which are
#' Run, ReleaseDate, LoadDate, spots, bases, spots_with_mates, avgLength,
#' size_MB, AssemblyName, download_path, Experiment, LibraryName, LibraryStrategy,
#' LibrarySelection, LibrarySource, LibraryLayout, InsertSize, InsertDev,
#' Platform, Model, SRAStudy, BioProject, Study_Pubmed_id, ProjectID, Sample,
#' BioSample, SampleType, TaxID, ScientificName, SampleName, g1k_pop_code, source,
#' g1k_analysis_group, Subject_ID, Sex, Disease, Tumor, Affection_Status, Analyte_Type,
#' Histological_Type, Body_Site, CenterName, Submission, dbgap_study_accession,
#' Consent, RunHash, and ReadHash.
#'
#' @details
#' Frequently Used Options:
#' General:
#' -h 	| 	--help 	Displays ALL options, general usage, and version information.
#' -V 	| 	--version 	Display the version of the program.
#' Data formatting:
#'   --split-files 	Dump each read into separate file. Files will receive suffix corresponding to read number.
#' --split-spot 	Split spots into individual reads.
#' --fasta <[line width]> 	FASTA only, no qualities. Optional line wrap width (set to zero for no wrapping).
#' -I 	| 	--readids 	Append read id after spot id as 'accession.spot.readid' on defline.
#' -F 	| 	--origfmt 	Defline contains only original sequence name.
#' -C 	| 	--dumpcs <[cskey]> 	Formats sequence using color space (default for SOLiD). "cskey" may be specified for translation.
#' -B 	| 	--dumpbase 	Formats sequence using base space (default for other than SOLiD).
#' -Q 	| 	--offset <integer> 	Offset to use for ASCII quality scores. Default is 33 ("!").
#' Filtering:
#'   -N 	| 	--minSpotId <rowid> 	Minimum spot id to be dumped. Use with "X" to dump a range.
#' -X 	| 	--maxSpotId <rowid> 	Maximum spot id to be dumped. Use with "N" to dump a range.
#' -M 	| 	--minReadLen <len> 	Filter by sequence length >= <len>
#'   --skip-technical 	Dump only biological reads.
#' --aligned 	Dump only aligned sequences. Aligned datasets only; see sra-stat.
#' --unaligned 	Dump only unaligned sequences. Will dump all for unaligned datasets.
#' Workflow and piping:
#'   -O 	| 	--outdir <path> 	Output directory, default is current working directory ('.').
#' -Z 	| 	--stdout 	Output to stdout, all split data become joined into single stream.
#' --gzip 	Compress output using gzip.
#' --bzip2 	Compress output using bzip2.
#'
#' @import funcTools
#' @import rstudioapi
#' @export
#' @examples {
#' \dontrun{
#' searchSrrID()
#' searchSrrID("PRJNA543132")
#' }
#' }
downloadSrr = function(srrIDs = c("SRR9063863", "SRR9063864"), timeout = 3600*12,
OutDir = "./", multipleDownload = 1){
stopifnot(length(srrIDs) > 0)
stopifnot((timeout<-as.integer(timeout)) > 0)
stopifnot((multipleDownload<-as.integer(multipleDownload)) > 0)
if (multipleDownload > 1){
stopifnot("jobRunScript" %in% ls("package:rstudioapi"))
}
if(!dir.exists(OutDir)){
dir.create(OutDir, recursive = TRUE)
}
if (multipleDownload == 1 | length(srrIDs) == 1){
srrIDs = paste0(srrIDs, collapse = " ")
cmd = sprintf('fastq-dump %s --split-files -X 1000 -O "%s" --gzip',
srrIDs, normalizePath(OutDir))
system("which fastq-dump")
system.time({
res1 = system(cmd, intern = T, timeout = timeout)
})
} else {
nBatch = ceiling(length(srrIDs) / multipleDownload)
tmpFiles = c()
for (ni in 1:nBatch){
m = ((ni -1)*multipleDownload+1) : min(length(srrIDs), (ni)*multipleDownload)
if (length(m) > 1){
for (mi in m[-length(m)]){
script = sprintf("echo 'system(\"fastq-dump %s --split-files -X 1000 -O %s, --gzip\", intern = FALSE, timeout = %s)'",
mi, normalizePath(OutDir), timeout)
tmpFile = tempfile(pattern = "file", fileext = ".R", tmpdir = tempdir())
system(paste0(script, " > ", tmpFile))
rstudioapi::jobRunScript(path = tmpFile, importEnv = TRUE)
}
}
tmpFile = tempfile(pattern = "file", fileext = ".R", tmpdir = tempdir())
script = sprintf("echo 'sink(%s); system(\"fastq-dump %s --split-files -X 1000 -O %s --gzip\", intern = TRUE, timeout = %s)'",
paste0(tmpFile, ".log"), m, normalizePath(OutDir), timeout)
system(paste0(script, " > ", tmpFile))
rstudioapi::jobRunScript(path = tmpFile, importEnv = TRUE)
tmpFiles = c(tmpFiles, tmpFile)
}
res1 = tmpFiles
}
return(res1)
}
x = searchSrrID()
library(funcTools)
x = searchSrrID()
x$Run
srrIDs = x$Run
timeout = 3600*12
OutDir = "downloadSRR"
OutDir = "./downloadSRR"
multipleDownload = 3
stopifnot(length(srrIDs) > 0)
stopifnot((timeout<-as.integer(timeout)) > 0)
stopifnot((multipleDownload<-as.integer(multipleDownload)) > 0)
if (multipleDownload > 1){
stopifnot("jobRunScript" %in% ls("package:rstudioapi"))
}
library(rstudioapi)
if (multipleDownload > 1){
stopifnot("jobRunScript" %in% ls("package:rstudioapi"))
}
if(!dir.exists(OutDir)){
dir.create(OutDir, recursive = TRUE)
}
multipleDownload == 1 | length(srrIDs) == 1
nBatch = ceiling(length(srrIDs) / multipleDownload)
tmpFiles = c()
nBatch
srrIDs = x$Run[1:5]
stopifnot(length(srrIDs) > 0)
stopifnot((timeout<-as.integer(timeout)) > 0)
stopifnot((multipleDownload<-as.integer(multipleDownload)) > 0)
if (multipleDownload > 1){
stopifnot("jobRunScript" %in% ls("package:rstudioapi"))
}
if(!dir.exists(OutDir)){
dir.create(OutDir, recursive = TRUE)
}
nBatch = ceiling(length(srrIDs) / multipleDownload)
tmpFiles = c()
nBatch
ni = 1
m = ((ni -1)*multipleDownload+1) : min(length(srrIDs), (ni)*multipleDownload)
m
length(m) > 1
m[-length(m)]
mi = 1
script = sprintf("echo 'system(\"fastq-dump %s --split-files -X 1000 -O %s, --gzip\", intern = FALSE, timeout = %s)'",
mi, normalizePath(OutDir), timeout)
tmpFile = tempfile(pattern = "file", fileext = ".R", tmpdir = tempdir())
script
system(paste0(script, " > ", tmpFile))
tmpFile
script = sprintf("echo 'sink(%s); system(\"fastq-dump %s --split-files -X 1000 -O %s, --gzip\", intern = FALSE, timeout = %s)'",
paste0(tmpFile, ".log"), mi, normalizePath(OutDir), timeout)
tmpFile = tempfile(pattern = "file", fileext = ".R", tmpdir = tempdir())
system(paste0(script, " > ", tmpFile))
tmpFile
script = sprintf("echo 'sink(\"%s\"); system(\"fastq-dump %s --split-files -X 1000 -O %s, --gzip\", intern = FALSE, timeout = %s)'",
paste0(tmpFile, ".log"), mi, normalizePath(OutDir), timeout)
tmpFile = tempfile(pattern = "file", fileext = ".R", tmpdir = tempdir())
system(paste0(script, " > ", tmpFile))
tmpFile
rstudioapi::jobRunScript(path = tmpFile, importEnv = TRUE)
for (mi in m[-length(m)]){
script = sprintf("echo 'sink(\"%s\"); system(\"fastq-dump %s --split-files -X 1000 -O %s --gzip\", intern = FALSE, timeout = %s)'",
paste0(tmpFile, ".log"), mi, normalizePath(OutDir), timeout)
tmpFile = tempfile(pattern = "file", fileext = ".R", tmpdir = tempdir())
system(paste0(script, " > ", tmpFile))
rstudioapi::jobRunScript(path = tmpFile, importEnv = TRUE)
}
multipleDownload == 1 | length(srrIDs) == 1
srrIDs = paste0(srrIDs, collapse = " ")
cmd = sprintf('fastq-dump %s --split-files -X 1000 -O "%s" --gzip',
srrIDs, normalizePath(OutDir))
system("which fastq-dump")
system.time({
res1 = system(cmd, intern = T, timeout = timeout)
})
script
stopifnot(length(srrIDs) > 0)
stopifnot((timeout<-as.integer(timeout)) > 0)
stopifnot((multipleDownload<-as.integer(multipleDownload)) > 0)
if (multipleDownload > 1){
stopifnot("jobRunScript" %in% ls("package:rstudioapi"))
}
if(!dir.exists(OutDir)){
dir.create(OutDir, recursive = TRUE)
}
if (multipleDownload == 1 | length(srrIDs) == 1){
srrIDs = paste0(srrIDs, collapse = " ")
cmd = sprintf('fastq-dump %s --split-files -X 1000 -O "%s" --gzip',
srrIDs, normalizePath(OutDir))
system("which fastq-dump")
system.time({
res1 = system(cmd, intern = T, timeout = timeout)
})
} else {
nBatch = ceiling(length(srrIDs) / multipleDownload)
tmpFiles = c()
for (ni in 1:nBatch){
m = ((ni -1)*multipleDownload+1) : min(length(srrIDs), (ni)*multipleDownload)
if (length(m) > 1){
for (mi in m[-length(m)]){
script = sprintf("echo 'sink(\"%s\"); system(\"fastq-dump %s --split-files -X 1000 -O %s --gzip\", intern = FALSE, timeout = %s)'",
paste0(tmpFile, ".log"), srrIDs[mi], normalizePath(OutDir), timeout)
tmpFile = tempfile(pattern = "file", fileext = ".R", tmpdir = tempdir())
system(paste0(script, " > ", tmpFile))
rstudioapi::jobRunScript(path = tmpFile, importEnv = TRUE)
}
}
tmpFile = tempfile(pattern = "file", fileext = ".R", tmpdir = tempdir())
script = sprintf("echo 'sink(\"%s\"); system(\"fastq-dump %s --split-files -X 1000 -O %s --gzip\", intern = TRUE, timeout = %s)'",
paste0(tmpFile, ".log"), srrIDs[m], normalizePath(OutDir), timeout)
system(paste0(script, " > ", tmpFile))
rstudioapi::jobRunScript(path = tmpFile, importEnv = TRUE)
tmpFiles = c(tmpFiles, tmpFile)
}
res1 = tmpFiles
}
multipleDownload
multipleDownload
stopifnot(length(srrIDs) > 0)
stopifnot((timeout<-as.integer(timeout)) > 0)
stopifnot((multipleDownload<-as.integer(multipleDownload)) > 0)
multipleDownload
if (multipleDownload > 1){
stopifnot("jobRunScript" %in% ls("package:rstudioapi"))
}
if(!dir.exists(OutDir)){
dir.create(OutDir, recursive = TRUE)
}
multipleDownload == 1 | length(srrIDs) == 1
srrIDs
multipleDownload
multipleDownload == 1
multipleDownload == 1 | length(srrIDs) == 1
length(srrIDs)
srrIDs = x$Run[1:5]
multipleDownload == 1 | length(srrIDs) == 1
if (multipleDownload == 1 | length(srrIDs) == 1){
# srrIDs = paste0(srrIDs, collapse = " ")
cmd = sprintf('fastq-dump %s --split-files -X 1000 -O "%s" --gzip',
paste0(srrIDs, collapse = " "), normalizePath(OutDir))
system("which fastq-dump")
system.time({
res1 = system(cmd, intern = T, timeout = timeout)
})
} else {
nBatch = ceiling(length(srrIDs) / multipleDownload)
tmpFiles = c()
for (ni in 1:nBatch){
m = ((ni -1)*multipleDownload+1) : min(length(srrIDs), (ni)*multipleDownload)
if (length(m) > 1){
for (mi in m[-length(m)]){
script = sprintf("echo 'sink(\"%s\"); system(\"fastq-dump %s --split-files -X 1000 -O %s --gzip\", intern = FALSE, timeout = %s)'",
paste0(tmpFile, ".log"), srrIDs[mi], normalizePath(OutDir), timeout)
tmpFile = tempfile(pattern = "file", fileext = ".R", tmpdir = tempdir())
system(paste0(script, " > ", tmpFile))
rstudioapi::jobRunScript(path = tmpFile, importEnv = TRUE)
}
}
tmpFile = tempfile(pattern = "file", fileext = ".R", tmpdir = tempdir())
script = sprintf("echo 'sink(\"%s\"); system(\"fastq-dump %s --split-files -X 1000 -O %s --gzip\", intern = TRUE, timeout = %s)'",
paste0(tmpFile, ".log"), srrIDs[m], normalizePath(OutDir), timeout)
system(paste0(script, " > ", tmpFile))
rstudioapi::jobRunScript(path = tmpFile, importEnv = TRUE)
tmpFiles = c(tmpFiles, tmpFile)
}
res1 = tmpFiles
}
nBatch = ceiling(length(srrIDs) / multipleDownload)
tmpFiles = c()
for (ni in 1:nBatch){
m = ((ni -1)*multipleDownload+1) : min(length(srrIDs), (ni)*multipleDownload)
if (length(m) > 1){
for (mi in m[-length(m)]){
script = sprintf("echo 'sink(\"%s\"); system(\"fastq-dump %s --split-files -X 1000 -O %s --gzip\", intern = FALSE, timeout = %s)'",
paste0(tmpFile, ".log"), srrIDs[mi], normalizePath(OutDir), timeout)
tmpFile = tempfile(pattern = "file", fileext = ".R", tmpdir = tempdir())
system(paste0(script, " > ", tmpFile))
rstudioapi::jobRunScript(path = tmpFile, importEnv = TRUE)
}
}
tmpFile = tempfile(pattern = "file", fileext = ".R", tmpdir = tempdir())
script = sprintf("echo 'sink(\"%s\"); system(\"fastq-dump %s --split-files -X 1000 -O %s --gzip\", intern = TRUE, timeout = %s)'",
paste0(tmpFile, ".log"), srrIDs[m], normalizePath(OutDir), timeout)
system(paste0(script, " > ", tmpFile))
rstudioapi::jobRunScript(path = tmpFile, importEnv = TRUE)
tmpFiles = c(tmpFiles, tmpFile)
}
res1 = tmpFiles
ni
m
srrIDs[m]
nBatch = ceiling(length(srrIDs) / multipleDownload)
tmpFiles = c()
for (ni in 1:nBatch){
m = ((ni -1)*multipleDownload+1) : min(length(srrIDs), (ni)*multipleDownload)
if (length(m) > 1){
for (mi in m[-length(m)]){
script = sprintf("echo 'sink(\"%s\"); system(\"fastq-dump %s --split-files -X 1000 -O %s --gzip\", intern = FALSE, timeout = %s)'",
paste0(tmpFile, ".log"), srrIDs[mi], normalizePath(OutDir), timeout)
tmpFile = tempfile(pattern = "file", fileext = ".R", tmpdir = tempdir())
system(paste0(script, " > ", tmpFile))
rstudioapi::jobRunScript(path = tmpFile, importEnv = TRUE)
}
}
tmpFile = tempfile(pattern = "file", fileext = ".R", tmpdir = tempdir())
script = sprintf("echo 'sink(\"%s\"); system(\"fastq-dump %s --split-files -X 1000 -O %s --gzip\", intern = TRUE, timeout = %s)'",
paste0(tmpFile, ".log"), srrIDs[m[length(m)]], normalizePath(OutDir), timeout)
system(paste0(script, " > ", tmpFile))
rstudioapi::jobRunScript(path = tmpFile, importEnv = TRUE)
tmpFiles = c(tmpFiles, tmpFile)
}
res1 = tmpFiles
#'
#' @import funcTools
#' @import rstudioapi
#' @export
#' @examples {
#' \dontrun{
#' searchSrrID()
#' searchSrrID("PRJNA543132")
#' }
#' }
downloadSrr = function(srrIDs = c("SRR9063863", "SRR9063864"), timeout = 3600*12,
OutDir = "./", multipleDownload = 1){
stopifnot(length(srrIDs) > 0)
stopifnot((timeout<-as.integer(timeout)) > 0)
stopifnot((multipleDownload<-as.integer(multipleDownload)) > 0)
if (multipleDownload > 1){
stopifnot("jobRunScript" %in% ls("package:rstudioapi"))
}
if(!dir.exists(OutDir)){
dir.create(OutDir, recursive = TRUE)
}
if (multipleDownload == 1 | length(srrIDs) == 1){
# srrIDs = paste0(srrIDs, collapse = " ")
cmd = sprintf('fastq-dump %s --split-files -O "%s" --gzip',
paste0(srrIDs, collapse = " "), normalizePath(OutDir))
system("which fastq-dump")
system.time({
res1 = system(cmd, intern = T, timeout = timeout)
})
} else {
nBatch = ceiling(length(srrIDs) / multipleDownload)
tmpFiles = c()
for (ni in 1:nBatch){
m = ((ni -1)*multipleDownload+1) : min(length(srrIDs), (ni)*multipleDownload)
if (length(m) > 1){
for (mi in m[-length(m)]){
script = sprintf("echo 'sink(\"%s\"); system(\"fastq-dump %s --split-files -O %s --gzip\", intern = FALSE, timeout = %s)'",
paste0(tmpFile, ".log"), srrIDs[mi], normalizePath(OutDir), timeout)
tmpFile = tempfile(pattern = "file", fileext = ".R", tmpdir = tempdir())
system(paste0(script, " > ", tmpFile))
rstudioapi::jobRunScript(path = tmpFile, importEnv = TRUE)
}
}
tmpFile = tempfile(pattern = "file", fileext = ".R", tmpdir = tempdir())
script = sprintf("echo 'sink(\"%s\"); system(\"fastq-dump %s --split-files -O %s --gzip\", intern = TRUE, timeout = %s)'",
paste0(tmpFile, ".log"), srrIDs[m[length(m)]], normalizePath(OutDir), timeout)
system(paste0(script, " > ", tmpFile))
rstudioapi::jobRunScript(path = tmpFile, importEnv = TRUE)
tmpFiles = c(tmpFiles, tmpFile)
}
res1 = tmpFiles
}
return(res1)
}
searchSrrID()
x = searchSrrID()$Run
x
xsearchSrrID
searchSrrID
x
x = searchSrrID("PRJNA540657")
head(x)
x = subset(x, SampleName %in% c("GSM3743639", "GSM3743640", "GSM3743641","GSM3743645", "GSM3743646", "GSM3743647"))$Run
x
#' searchSrrID("PRJNA543132")
#' downloadSrr(srrIDs = c("SRR9063863", "SRR9063864"), OutDir = "./down")
#' downloadSrr(srrIDs = c("SRR9063863", "SRR9063864"), OutDir = "./down", multipleDownload = 2)
#'
#' x = searchSrrID("PRJNA540657")
#' x = subset(x, SampleName %in% c("GSM3743639", "GSM3743640", "GSM3743641",
#'            "GSM3743645", "GSM3743646", "GSM3743647"))$Run
#' downloadSrr(srrIDs = x, OutDir = "./down", multipleDownload = 2)
#' }
#' }
downloadSrr = function(srrIDs = c("SRR9063863", "SRR9063864"), timeout = 3600*12,
OutDir = "./", multipleDownload = 1){
stopifnot(length(srrIDs) > 0)
stopifnot((timeout<-as.integer(timeout)) > 0)
stopifnot((multipleDownload<-as.integer(multipleDownload)) > 0)
if (multipleDownload > 1){
stopifnot("jobRunScript" %in% ls("package:rstudioapi"))
}
if(!dir.exists(OutDir)){
dir.create(OutDir, recursive = TRUE)
}
if (multipleDownload == 1 | length(srrIDs) == 1){
# srrIDs = paste0(srrIDs, collapse = " ")
cmd = sprintf('fastq-dump %s --split-files -O "%s" --gzip',
paste0(srrIDs, collapse = " "), normalizePath(OutDir))
system("which fastq-dump")
system.time({
res1 = system(cmd, intern = T, timeout = timeout)
})
} else {
nBatch = ceiling(length(srrIDs) / multipleDownload)
tmpFiles = c()
for (ni in 1:nBatch){
m = ((ni -1)*multipleDownload+1) : min(length(srrIDs), (ni)*multipleDownload)
for (mi in m){
script = sprintf("echo 'sink(\"%s\"); system(\"fastq-dump %s --split-files -O %s --gzip\", intern = FALSE, timeout = %s)'",
paste0(tmpFile, ".log"), srrIDs[mi], normalizePath(OutDir), timeout)
tmpFile = tempfile(pattern = "file", fileext = ".R", tmpdir = tempdir())
system(paste0(script, " > ", tmpFile))
rstudioapi::jobRunScript(path = tmpFile, importEnv = TRUE)
tmpFiles = c(tmpFiles, tmpFile)
}
}
res1 = tmpFiles
}
return(res1)
}
x = subset(x, SampleName %in% c("GSM3743639", "GSM3743640", "GSM3743641", "GSM3743645", "GSM3743646", "GSM3743647"))$Run
x = searchSrrID("PRJNA540657")
x = subset(x, SampleName %in% c("GSM3743639", "GSM3743640", "GSM3743641", "GSM3743645", "GSM3743646", "GSM3743647"))$Run
#' searchSrrID("PRJNA543132")
#' downloadSrr(srrIDs = c("SRR9063863", "SRR9063864"), OutDir = "./down")
#' downloadSrr(srrIDs = c("SRR9063863", "SRR9063864"), OutDir = "./down", multipleDownload = 2)
#'
#' x = searchSrrID("PRJNA540657")
#' x = subset(x, SampleName %in% c("GSM3743639", "GSM3743640", "GSM3743641",
#'            "GSM3743645", "GSM3743646", "GSM3743647"))$Run
#' downloadSrr(srrIDs = x, OutDir = "./down", multipleDownload = 3)
#' }
#' }
downloadSrr = function(srrIDs = c("SRR9063863", "SRR9063864"), timeout = 3600*12,
OutDir = "./", multipleDownload = 1){
stopifnot(length(srrIDs) > 0)
stopifnot((timeout<-as.integer(timeout)) > 0)
stopifnot((multipleDownload<-as.integer(multipleDownload)) > 0)
if (multipleDownload > 1){
stopifnot("jobRunScript" %in% ls("package:rstudioapi"))
}
if(!dir.exists(OutDir)){
dir.create(OutDir, recursive = TRUE)
}
if (multipleDownload == 1 | length(srrIDs) == 1){
# srrIDs = paste0(srrIDs, collapse = " ")
cmd = sprintf('fastq-dump %s --split-files -O "%s" --gzip',
paste0(srrIDs, collapse = " "), normalizePath(OutDir))
system("which fastq-dump")
system.time({
res1 = system(cmd, intern = T, timeout = timeout)
})
} else {
nBatch = ceiling(length(srrIDs) / multipleDownload)
tmpFiles = c()
for (ni in 1:nBatch){
m = ((ni -1)*multipleDownload+1) : min(length(srrIDs), (ni)*multipleDownload)
for (mi in m){
script = sprintf("echo 'sink(\"%s\"); system(\"fastq-dump %s --split-files -O %s --gzip\", intern = FALSE, timeout = %s)'",
paste0(tmpFile, ".log"), srrIDs[mi], normalizePath(OutDir), timeout)
tmpFile = tempfile(pattern = "file", fileext = ".R", tmpdir = tempdir())
system(paste0(script, " > ", tmpFile))
rstudioapi::jobRunScript(path = tmpFile, importEnv = TRUE)
tmpFiles = c(tmpFiles, tmpFile)
}
Sys.sleep(100)
}
res1 = tmpFiles
}
return(res1)
}
y = downloadSrr(srrIDs = x, OutDir = "./down", multipleDownload = 3)
system.time(y = downloadSrr(srrIDs = x, OutDir = "./down", multipleDownload = 1))
system.time({y = downloadSrr(srrIDs = x, OutDir = "./down", multipleDownload = 1)})
2754.109 /60
